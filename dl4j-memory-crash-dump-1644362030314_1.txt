Deeplearning4j OOM Exception Encountered for MultiLayerNetwork
Timestamp:                              2022-02-09 01:13:50.314
Thread ID                               1
Thread Name                             main


Stack Trace:
java.lang.OutOfMemoryError: Cannot allocate new LongPointer(2): totalBytes = 368, physicalBytes = 8602M
	at org.bytedeco.javacpp.LongPointer.<init>(LongPointer.java:88)
	at org.bytedeco.javacpp.LongPointer.<init>(LongPointer.java:53)
	at org.nd4j.linalg.cpu.nativecpu.ops.NativeOpExecutioner.createShapeInfo(NativeOpExecutioner.java:2016)
	at org.nd4j.linalg.api.shape.Shape.createShapeInformation(Shape.java:3247)
	at org.nd4j.linalg.api.ndarray.BaseShapeInfoProvider.createShapeInformation(BaseShapeInfoProvider.java:68)
	at org.nd4j.linalg.api.ndarray.BaseNDArray.<init>(BaseNDArray.java:180)
	at org.nd4j.linalg.api.ndarray.BaseNDArray.<init>(BaseNDArray.java:174)
	at org.nd4j.linalg.cpu.nativecpu.NDArray.<init>(NDArray.java:78)
	at org.nd4j.linalg.cpu.nativecpu.CpuNDArrayFactory.create(CpuNDArrayFactory.java:409)
	at org.nd4j.linalg.factory.Nd4j.create(Nd4j.java:4033)
	at org.nd4j.linalg.api.shape.Shape.newShapeNoCopy(Shape.java:2123)
	at org.deeplearning4j.nn.layers.convolution.ConvolutionLayer.preOutput(ConvolutionLayer.java:459)
	at org.deeplearning4j.nn.layers.convolution.ConvolutionLayer.activate(ConvolutionLayer.java:505)
	at org.deeplearning4j.nn.layers.AbstractLayer.activate(AbstractLayer.java:262)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.ffToLayerActivationsInWs(MultiLayerNetwork.java:1138)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.computeGradientAndScore(MultiLayerNetwork.java:2783)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.computeGradientAndScore(MultiLayerNetwork.java:2741)
	at org.deeplearning4j.optimize.solvers.BaseOptimizer.gradientAndScore(BaseOptimizer.java:174)
	at org.deeplearning4j.optimize.solvers.StochasticGradientDescent.optimize(StochasticGradientDescent.java:61)
	at org.deeplearning4j.optimize.Solver.optimize(Solver.java:52)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.fitHelper(MultiLayerNetwork.java:1752)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.fit(MultiLayerNetwork.java:1673)
	at MaizeDiseaseDetectionModel.main(MaizeDiseaseDetectionModel.java:134)
Caused by: java.lang.OutOfMemoryError: Physical memory usage is too high: physicalBytes (8602M) > maxPhysicalBytes (8080M)
	at org.bytedeco.javacpp.Pointer.deallocator(Pointer.java:700)
	at org.bytedeco.javacpp.Pointer.init(Pointer.java:126)
	at org.bytedeco.javacpp.LongPointer.allocateArray(Native Method)
	at org.bytedeco.javacpp.LongPointer.<init>(LongPointer.java:80)
	... 22 more


========== Memory Information ==========
----- Version Information -----
Deeplearning4j Version                  <could not determine>
Deeplearning4j CUDA                     <not present>

----- System Information -----
Operating System                        Microsoft Windows 10
CPU                                     Intel(R) Core(TM) i5-9500T CPU @ 2.20GHz
CPU Cores - Physical                    6
CPU Cores - Logical                     6
Total System Memory                      15.78 GiB (16943194112)

----- ND4J Environment Information -----
Data Type                               FLOAT
blas.vendor                             OPENBLAS
os                                      Windows 10
backend                                 CPU

----- Memory Configuration -----
JVM Memory: XMX                           3.95 GiB (4236247040)
JVM Memory: current                     168.00 MiB (176160768)
JavaCPP Memory: Max Bytes                 3.95 GiB (4236247040)
JavaCPP Memory: Max Physical              7.89 GiB (8472494080)
JavaCPP Memory: Current Bytes             368.00 B
JavaCPP Memory: Current Physical          5.00 GiB (5363683328)
Periodic GC Enabled                     false

----- Workspace Information -----
Workspaces: # for current thread        2
Current thread workspaces:
  Name                      State       Size                          # Cycles            
  WS_LAYER_WORKING_MEM      CLOSED           .00 B                    3                   
  WS_ALL_LAYERS_ACT         CLOSED      865.57 MiB (907620000)        1                   
Workspaces total size                   865.57 MiB (907620000)

----- Network Information -----
Network # Parameters                    1008295404
Parameter Memory                          3.76 GiB (4033181616)
Parameter Gradients Memory              <not allocated>
Updater                                 <not initialized>
Params + Gradient + Updater Memory           .00 B
Iteration Count                         0
Epoch Count                             0
Backprop Type                           Standard
Workspace Mode: Training                ENABLED
Workspace Mode: Inference               ENABLED
Number of Layers                        6
Layer Counts
  ConvolutionLayer                        2
  DenseLayer                              1
  OutputLayer                             1
  SubsamplingLayer                        2
Layer Parameter Breakdown
  Idx Name                 Layer Type           Layer # Parameters   Layer Parameter Memory
  0   layer0               ConvolutionLayer     2800                  10.94 KiB (11200)  
  1   layer1               SubsamplingLayer     0                         .00 B          
  2   layer2               ConvolutionLayer     90100                351.95 KiB (360400) 
  3   layer3               SubsamplingLayer     0                         .00 B          
  4   layer4               DenseLayer           1008200500             3.76 GiB (4032802000)
  5   layer5               OutputLayer          2004                   7.83 KiB (8016)   

----- Layer Helpers - Memory Use -----
Total Helper Count                      0
Helper Count w/ Memory                  0
Total Helper Persistent Memory Use           .00 B

----- Network Activations: Inferred Activation Shapes -----
Current Minibatch Size                  50
Input Shape                             [50, 3, 150, 150]
Idx Name                 Layer Type           Activations Type                           Activations Shape    # Elements   Memory      
0   layer0               ConvolutionLayer     InputTypeConvolutional(h=148,w=148,c=100,NCHW) [50, 100, 148, 148]  109520000    417.79 MiB (438080000)
1   layer1               SubsamplingLayer     InputTypeConvolutional(h=146,w=146,c=100,NCHW) [50, 100, 146, 146]  106580000    406.57 MiB (426320000)
2   layer2               ConvolutionLayer     InputTypeConvolutional(h=144,w=144,c=100,NCHW) [50, 100, 144, 144]  103680000    395.51 MiB (414720000)
3   layer3               SubsamplingLayer     InputTypeConvolutional(h=142,w=142,c=100,NCHW) [50, 100, 142, 142]  100820000    384.60 MiB (403280000)
4   layer4               DenseLayer           InputTypeFeedForward(500)                  [50, 500]            25000         97.66 KiB (100000)
5   layer5               OutputLayer          InputTypeFeedForward(4)                    [50, 4]              200            800.00 B  
Total Activations Memory                  1.57 GiB (1682500800)
Total Activations Memory (per ex)        32.09 MiB (33650016)
Total Activation Gradient Mem.            1.58 GiB (1696000000)
Total Activation Gradient Mem. (per ex)  32.35 MiB (33920000)

----- Network Training Listeners -----
Number of Listeners                     2
Listener 0                              org.deeplearning4j.ui.model.stats.StatsListener@20134094
Listener 1                              ScoreIterationListener(10)
